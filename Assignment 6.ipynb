{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "1. Use yeast dataset from UCI http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\n",
    "2. Remove the first column and use the last column as the target\n",
    "3. Only leave CYT and VAC classes\n",
    "4. Replace [0.3, 0.5, 0.7] in feature 2 to null\n",
    "5. Replace [0.26, 0.36, 0.64] in feature 3 to null\n",
    "6. Split the data\n",
    "\n",
    "7. Impute the data (or not, it's your call)\n",
    "8. Build a outlier detection model to classify VAC from CYT, i.e. 0 from 1\n",
    "9. Build a classifer using sample augmentation techniques to flassify VAC from CYT, i.e. 0 from 1\n",
    "10. Try different methods and hyper paramters\n",
    "\n",
    "11. Report perfromance using F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imblearn) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.17.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install imblearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from impyute.imputation.cs import mice\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from numpy import where\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "pd.options.mode.chained_assignment = None  # default='warn' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     object\n",
       "1    float64\n",
       "2    float64\n",
       "3    float64\n",
       "4    float64\n",
       "5    float64\n",
       "6    float64\n",
       "7    float64\n",
       "8    float64\n",
       "9     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset into a pandas dataframe\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data'\n",
    "yeast_data = pd.read_fwf(url,header= None)\n",
    "# dtypes for our columns\n",
    "yeast_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.500121</td>\n",
       "      <td>0.137299</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.499933</td>\n",
       "      <td>0.123924</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.500034</td>\n",
       "      <td>0.086670</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.261186</td>\n",
       "      <td>0.137098</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.504717</td>\n",
       "      <td>0.048351</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.075683</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.499885</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>0.276199</td>\n",
       "      <td>0.106491</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count      mean       std   min   25%   50%   75%   max\n",
       "1  1484.0  0.500121  0.137299  0.11  0.41  0.49  0.58  1.00\n",
       "2  1484.0  0.499933  0.123924  0.13  0.42  0.49  0.57  1.00\n",
       "3  1484.0  0.500034  0.086670  0.21  0.46  0.51  0.55  1.00\n",
       "4  1484.0  0.261186  0.137098  0.00  0.17  0.22  0.32  1.00\n",
       "5  1484.0  0.504717  0.048351  0.50  0.50  0.50  0.50  1.00\n",
       "6  1484.0  0.007500  0.075683  0.00  0.00  0.00  0.00  0.83\n",
       "7  1484.0  0.499885  0.057797  0.00  0.48  0.51  0.53  0.73\n",
       "8  1484.0  0.276199  0.106491  0.00  0.22  0.22  0.30  1.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics of the DataFrame\n",
    "yeast_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1     2     3     4    5    6     7     8    9\n",
       "0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22  MIT\n",
       "1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22  MIT\n",
       "2  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22  MIT\n",
       "3  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22  NUC\n",
       "4  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22  MIT"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we drop the first column as it is not needed for this problem\n",
    "yeast_data = yeast_data.iloc[: , 1:]\n",
    "yeast_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CYT    463\n",
       "NUC    429\n",
       "MIT    244\n",
       "ME3    163\n",
       "ME2     51\n",
       "ME1     44\n",
       "EXC     35\n",
       "VAC     30\n",
       "POX     20\n",
       "ERL      5\n",
       "Name: 9, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeast_data[9].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.22</td>\n",
       "      <td>CYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.30</td>\n",
       "      <td>CYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>CYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>CYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>CYT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1     2     3     4    5    6     7     8    9\n",
       "5   0.51  0.40  0.56  0.17  0.5  0.5  0.49  0.22  CYT\n",
       "9   0.40  0.39  0.60  0.15  0.5  0.0  0.58  0.30  CYT\n",
       "12  0.40  0.42  0.57  0.35  0.5  0.0  0.53  0.25  CYT\n",
       "15  0.46  0.44  0.52  0.11  0.5  0.0  0.50  0.22  CYT\n",
       "16  0.47  0.39  0.50  0.11  0.5  0.0  0.49  0.40  CYT"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeast_data = yeast_data.loc[(yeast_data[9] == \"CYT\") | (yeast_data[9] == \"VAC\")]\n",
    "yeast_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0\n",
       "2    26\n",
       "3     5\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeast_data[2].replace({0.3:np.NaN, 0.5:np.NaN, 0.7:np.NaN}, inplace=True)\n",
    "yeast_data[3].replace({0.26:np.NaN, 0.36:np.NaN, 0.64:np.NaN}, inplace=True)\n",
    "#count the NaNs per column\n",
    "yeast_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to classify VAC=1 and CYT=0. This way, we will get F-1 score for pos_label=1, i.e for VAC which is going to be a hard task to optimise, since we do not have many occurences of VAC in our dataset. So, the F-1 scores are going to be low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns but the last\n",
    "X = yeast_data.iloc[: , :-1]\n",
    "# the last column of the df \n",
    "y = yeast_data.iloc[:,-1:]\n",
    "y.replace({(\"CYT\"): 0}, inplace=True)\n",
    "y.replace({(\"VAC\"): 1}, inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Simple imputation with mean\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X_train)\n",
    "X_train_imp = imp.transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)\n",
    "\n",
    "#some manipulation of y to skip errors\n",
    "y_train_array = y_train.to_numpy().ravel()\n",
    "y_test_array = y_test.to_numpy().ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training took 1.16 seconds\n",
      "Best cross-validation score: 0.38\n",
      "Test set score: 0.25\n",
      "Best parameters: {'classifier': SVC(C=1000, gamma=1), 'classifier__C': 1000, 'classifier__gamma': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Benchmark model with no outlier detection method\n",
    "pipe = Pipeline([('classifier', SVC())])\n",
    "\n",
    "param_grid = [\n",
    "     {'classifier': [SGDClassifier()],\n",
    "      'classifier__average': [True, False],\n",
    "      'classifier__l1_ratio': [0.001, 0.01, 0.1, 1],\n",
    "      'classifier__alpha': [0.001, 0.01, 0.1, 1]},\n",
    "    \n",
    "     {'classifier': [SVC()],\n",
    "      'classifier__gamma':[0.001, 0.01, 0.1, 1],\n",
    "      'classifier__C': [100,1000,1250,1500]},\n",
    "    \n",
    "     {'classifier': [LogisticRegression()], \n",
    "      'classifier__C': [0.001, 0.01, 0.1, 1]}]\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv = StratifiedKFold(), scoring='f1')\n",
    "start = time()\n",
    "grid_search.fit(X_train_imp, y_train_array)\n",
    "   \n",
    "print(\"Model training took %.2f seconds\"\n",
    "    % ((time() - start)))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test_imp, y_test_array)))\n",
    "print(\"Best parameters: {}\\n\".format(grid_search.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN(eps=0.1, min_samples=20)\n",
      "Total occurences of \"0\" in y:  135\n",
      "Total occurences of \"1\" in y:  10\n",
      "Model training took 0.86 seconds\n",
      "Best cross-validation score: 0.00\n",
      "Test set score: 0.00\n",
      "Best parameters: {'classifier': SGDClassifier(alpha=0.001, average=True, l1_ratio=0.001), 'classifier__alpha': 0.001, 'classifier__average': True, 'classifier__l1_ratio': 0.001}\n",
      "\n",
      "IsolationForest(contamination=0.05)\n",
      "Total occurences of \"0\" in y:  304\n",
      "Total occurences of \"1\" in y:  23\n",
      "Model training took 1.10 seconds\n",
      "Best cross-validation score: 0.26\n",
      "Test set score: 0.22\n",
      "Best parameters: {'classifier': SVC(C=1000, gamma=1), 'classifier__C': 1000, 'classifier__gamma': 1}\n",
      "\n",
      "LocalOutlierFactor(contamination=0.5)\n",
      "Total occurences of \"0\" in y:  165\n",
      "Total occurences of \"1\" in y:  8\n",
      "Model training took 0.97 seconds\n",
      "Best cross-validation score: 0.00\n",
      "Test set score: 0.00\n",
      "Best parameters: {'classifier': SGDClassifier(alpha=0.001, average=True, l1_ratio=0.001), 'classifier__alpha': 0.001, 'classifier__average': True, 'classifier__l1_ratio': 0.001}\n",
      "\n",
      "EllipticEnvelope(contamination=0.05)\n",
      "Total occurences of \"0\" in y:  303\n",
      "Total occurences of \"1\" in y:  24\n",
      "Model training took 1.11 seconds\n",
      "Best cross-validation score: 0.38\n",
      "Test set score: 0.20\n",
      "Best parameters: {'classifier': SVC(C=1250, gamma=1), 'classifier__C': 1250, 'classifier__gamma': 1}\n",
      "\n",
      "OneClassSVM(gamma=1, nu=0.05)\n",
      "Total occurences of \"0\" in y:  306\n",
      "Total occurences of \"1\" in y:  21\n",
      "Model training took 1.17 seconds\n",
      "Best cross-validation score: 0.23\n",
      "Test set score: 0.44\n",
      "Best parameters: {'classifier': SVC(C=1000, gamma=1), 'classifier__C': 1000, 'classifier__gamma': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "methods = [DBSCAN(eps = 0.10, min_samples = 20), \n",
    "           IsolationForest(n_estimators=100, contamination=.05), \n",
    "           LocalOutlierFactor(n_neighbors=20, contamination=.50), \n",
    "           EllipticEnvelope(contamination=.05), \n",
    "           OneClassSVM(kernel=\"rbf\", gamma=1, nu=0.05)]\n",
    "for outliers in methods:\n",
    "    # Build an outlier detection model to classify VAC from CYT\n",
    "     \n",
    "    pred = outliers.fit_predict(X_train_imp)\n",
    "    # the negatives are the outliers.\n",
    "    exists = 0 in pred\n",
    "    if exists == True:\n",
    "        filter_ = 0 \n",
    "    else:\n",
    "        filter_ = 1\n",
    "    anom_index = where(pred == filter_)\n",
    "    X_train_out = X_train_imp[anom_index]\n",
    "    y_train_out= y_train_array[anom_index]\n",
    "    count_arr = np.bincount(y_train_out)\n",
    "    print(outliers)\n",
    "    # Count occurrence of element '3' in numpy array\n",
    "    print('Total occurences of \"0\" in y: ', count_arr[0])\n",
    "    # Count occurrence of element '5' in numpy array\n",
    "    print('Total occurences of \"1\" in y: ', count_arr[1])\n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv = StratifiedKFold(), scoring='f1')\n",
    "\n",
    "    start = time()\n",
    "    grid_search.fit(X_train_out, y_train_out)\n",
    "    \n",
    "    print(\"Model training took %.2f seconds\"\n",
    "        % ((time() - start)))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    print(\"Test set score: {:.2f}\".format(grid_search.score(X_test_imp, y_test_array)))\n",
    "    print(\"Best parameters: {}\\n\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 Test Score: 0.444\n"
     ]
    }
   ],
   "source": [
    "outliers= OneClassSVM(gamma=1, nu=0.05)\n",
    "pred = outliers.fit_predict(X_train_imp)\n",
    "anom_index = where(pred == 1)\n",
    "X_train_out = X_train_imp[anom_index]\n",
    "y_train_out= y_train_array[anom_index]\n",
    "# optimal model\n",
    "model = SVC(C=1000, gamma=1)\n",
    "# train model\n",
    "model.fit(X_train_out, y_train_out)\n",
    "# test score\n",
    "y_predicted = model.predict(X_test_imp)\n",
    "score = f1_score(y_test, y_predicted)\n",
    "print(\"F-1 Test Score: {0:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total occurences of \"0\" in y_predicted:  145\n",
      "Total occurences of \"1\" in y_predicted:  3\n",
      "Total occurences of \"0\" in y_test:  142\n",
      "Total occurences of \"1\" in y_test:  6\n"
     ]
    }
   ],
   "source": [
    "count_arr = np.bincount(y_predicted)\n",
    "\n",
    "# Count occurrence of element '3' in numpy array\n",
    "print('Total occurences of \"0\" in y_predicted: ', count_arr[0])\n",
    "# Count occurrence of element '5' in numpy array\n",
    "print('Total occurences of \"1\" in y_predicted: ', count_arr[1])\n",
    "\n",
    "count_arr = np.bincount(y_test_array)\n",
    "\n",
    "# Count occurrence of element '3' in numpy array\n",
    "print('Total occurences of \"0\" in y_test: ', count_arr[0])\n",
    "# Count occurrence of element '5' in numpy array\n",
    "print('Total occurences of \"1\" in y_test: ', count_arr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 321\n",
      "Class 1: 24\n",
      "Proportion: 13.38 : 1\n"
     ]
    }
   ],
   "source": [
    "color = ['blue','orange']\n",
    "\n",
    "target_count = y_train.value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEeCAYAAABxO1VsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATJUlEQVR4nO3df7BkZX3n8fcnDEJQ4gBzJTAMGYK4G9wsY+oGsdQU6hqBSmrIVkJQo5Msu5NKQUorP3aJSSnJSsokazRulFpSUEyCPyCigd2wUWTZqLURvCAgP0RnVXZmMjJXYADFYAa++0efgeZy73TfH3177jPvV1XXPed5nnPOt2d6PvfM0+d0p6qQJLXlB8ZdgCRp6RnuktQgw12SGmS4S1KDDHdJapDhLkkNMtylOSSZSPKVJD847lpmk+SQrr6Jcdei/Y/hrrFK8qYkU0m+k2Rnkv+Z5FXLcNxK8uIBwy4Erqiq73Xb/O8k/37Utc1l5vGr6gngcnp1Ss9iuGtskvwG8H7gD4GjgeOBDwEbx1gW0DsrBjYBVy7hPlct1b76fATY1NUrPc1w11gkeSHwB8D5VfWJqvpuVf1zVf33qvrtbswhSd6f5B+7x/v3hliSX07y+Rn7fPpsPMkVST6Y5G+TPJbk5iQndn2f7Ta5o/sfwy/OUuLLgd1Vtb3b5mLg1cCfd9v8edf+Z0m2JXk0ya1JXt1Xz0VJPp7kyiSPAr+c5IQkn+1q+kxX45V925yW5P8k2Z3kjiSn7+v4XX0PA6ct/G9DLTLcNS6vAA4FPrmPMb9LL7Q2AKcApwK/N49jnAv8PnAEsBW4GKCqfqrrP6WqXlBVV82y7Y8D9+1dqarfBT4HXNBtc0HX9cWuviPpnUX/dZJD+/azEfg4sBr4cDfmFuAo4CLgLXsHJlkL/C3w7m5/vwVck2RiH8cHuJfen4/0NMNd43IU8O2q2rOPMW8G/qCqdlXVNL2gfss+xs/0yaq6pTvGh+mF8LBWA48NGlRVV1bVg1W1p6reCxwC/Iu+If9QVX9TVU8BE8BPAu+squ9X1eeB6/rG/hJwfVVdX1VPVdUNwBRw1oAyHuvqlZ5muGtcHgTWDJiHPha4v2/9/q5tWN/qW34ceME8tn0YOHzQoCS/leTeJI8k2Q28EFjTN2Rb3/KxwENV9fgc/T8C/EI3JbO729+rgGMGlHE4sHtQrTqwGO4al38AngDO3seYf6QXeHsd37UBfBc4bG9Hkh9e4vruBF4yo+1ZH6Haza//R+Ac4IiqWg08AmSObXYCRyY5rK9tXd/yNuCvqmp13+P5VfWe2Y7f58eAO4Z4TjqAGO4ai6p6BHgn8MEkZyc5LMnBSc5M8sfdsI8Cv9ddb76mG7/3zcc7gJcm2dDNcV80zxIeAH50H/23AKu7efC5tjkc2ANMA6uSvBP4obl2WFX305tmuSjJ85K8AvjZviFXAj+b5A1JDkpyaJLTkxw3V81dfUcCX9jHc9EByHDX2HRz1L9B703SaXpnrhcAf9MNeTe9MLwT+DJwW9dGVX2V3tU2nwG+BjzrypkhXARs6aY/zpmltu8DV9CbB9/rz4CfT/Jwkg8AnwL+DvgqvSmjf+LZ0yyzeTO9N5Mf7J7LVfT+B0NVbaP3Buw7eObP47d55t/pzOMDvAnY0l3zLj0tflmHNLvuzs/PAS/beyPTCI5xFfCVqnrXArY9hN7/YH6qqnYteXFa0Qx3aRkl+UngIeAbwE/T+1/KK6rqS+OsS+0ZxR1zkub2w8An6F0Kuh34NYNdo+CZuyQ1yDdUJalBhrskNWi/mHNfs2ZNrV+/ftxlSNKKcuutt367qmb9PP/9ItzXr1/P1NTUuMuQpBUlyf1z9TktI0kNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQfnET00qRDB6j4fmZddLoeOYuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNGhjuSQ5NckuSO5LcneT3u/YTktycZGuSq5I8r2s/pFvf2vWvH/FzkCTNMMyZ+xPAa6vqFGADcEaS04A/At5XVS8GHgbO68afBzzctb+vGydJWkYDw716vtOtHtw9Cngt8PGufQtwdre8sVun639d4qeySNJyGmrOPclBSW4HdgE3AP8X2F1Ve7oh24G13fJaYBtA1/8IcNQS1ixJGmCocK+qJ6tqA3AccCrwLxd74CSbk0wlmZqenl7s7iRJfeZ1tUxV7QZuAl4BrE6y9yODjwN2dMs7gHUAXf8LgQdn2delVTVZVZMTExMLq16SNKthrpaZSLK6W/5B4PXAvfRC/ue7YZuAa7vl67p1uv7/VeUnd0vSchrmyzqOAbYkOYjeL4Orq+p/JLkH+FiSdwNfAi7rxl8G/FWSrcBDwLkjqFuStA8Dw72q7gReNkv71+nNv89s/yfgF5akOknSgniHqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNGhjuSdYluSnJPUnuTvK2rv2iJDuS3N49zurb5neSbE1yX5I3jPIJSJKea9UQY/YAv1lVtyU5HLg1yQ1d3/uq6r/0D05yMnAu8FLgWOAzSV5SVU8uZeGSpLkNPHOvqp1VdVu3/BhwL7B2H5tsBD5WVU9U1TeArcCpS1GsJGk485pzT7IeeBlwc9d0QZI7k1ye5IiubS2wrW+z7ez7l4EkaYkNHe5JXgBcA7y9qh4FLgFOBDYAO4H3zufASTYnmUoyNT09PZ9NJUkDDBXuSQ6mF+wfrqpPAFTVA1X1ZFU9BfwFz0y97ADW9W1+XNf2LFV1aVVNVtXkxMTEYp6DJGmGYa6WCXAZcG9V/Wlf+zF9w34OuKtbvg44N8khSU4ATgJuWbqSJUmDDHO1zCuBtwBfTnJ71/YO4I1JNgAFfBP4VYCqujvJ1cA99K60Od8rZSRpeQ0M96r6PJBZuq7fxzYXAxcvoi5J0iJ4h6okNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBA8M9ybokNyW5J8ndSd7WtR+Z5IYkX+t+HtG1J8kHkmxNcmeSnxj1k5AkPdswZ+57gN+sqpOB04Dzk5wMXAjcWFUnATd26wBnAid1j83AJUtetSRpnwaGe1XtrKrbuuXHgHuBtcBGYEs3bAtwdre8EfjL6vkCsDrJMUtduCRpbvOac0+yHngZcDNwdFXt7Lq+BRzdLa8FtvVttr1rkyQtk6HDPckLgGuAt1fVo/19VVVAzefASTYnmUoyNT09PZ9NJUkDDBXuSQ6mF+wfrqpPdM0P7J1u6X7u6tp3AOv6Nj+ua3uWqrq0qiaranJiYmKh9UuSZjHM1TIBLgPurao/7eu6DtjULW8Cru1rf2t31cxpwCN90zeSpGWwaogxrwTeAnw5ye1d2zuA9wBXJzkPuB84p+u7HjgL2Ao8DvzKUhYsSRpsYLhX1eeBzNH9ulnGF3D+IuuSJC2Cd6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KCB4Z7k8iS7ktzV13ZRkh1Jbu8eZ/X1/U6SrUnuS/KGURUuSZrbMGfuVwBnzNL+vqra0D2uB0hyMnAu8NJumw8lOWipipUkDWdguFfVZ4GHhtzfRuBjVfVEVX0D2Aqcuoj6JEkLsJg59wuS3NlN2xzRta0FtvWN2d61SZKW0ULD/RLgRGADsBN473x3kGRzkqkkU9PT0wssQ5I0mwWFe1U9UFVPVtVTwF/wzNTLDmBd39DjurbZ9nFpVU1W1eTExMRCypAkzWFB4Z7kmL7VnwP2XklzHXBukkOSnACcBNyyuBIlSfO1atCAJB8FTgfWJNkOvAs4PckGoIBvAr8KUFV3J7kauAfYA5xfVU+OpHJJ0pxSVeOugcnJyZqamhp3GQMl466gLfvBS09a0ZLcWlWTs/V5h6okNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRoY7kkuT7IryV19bUcmuSHJ17qfR3TtSfKBJFuT3JnkJ0ZZvCRpdsOcuV8BnDGj7ULgxqo6CbixWwc4Ezipe2wGLlmaMiVJ8zEw3Kvqs8BDM5o3Alu65S3A2X3tf1k9XwBWJzlmiWqVJA1poXPuR1fVzm75W8DR3fJaYFvfuO1dmyRpGS36DdWqKqDmu12SzUmmkkxNT08vtgxJUp+FhvsDe6dbup+7uvYdwLq+ccd1bc9RVZdW1WRVTU5MTCywDEnSbBYa7tcBm7rlTcC1fe1v7a6aOQ14pG/6RpK0TFYNGpDko8DpwJok24F3Ae8Brk5yHnA/cE43/HrgLGAr8DjwKyOoWZI0wMBwr6o3ztH1ulnGFnD+YouSJC2Od6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KBVi9k4yTeBx4AngT1VNZnkSOAqYD3wTeCcqnp4cWVKkuZjKc7cX1NVG6pqslu/ELixqk4CbuzWJUnLaBTTMhuBLd3yFuDsERxDkrQPiw33Aj6d5NYkm7u2o6tqZ7f8LeDoRR5DkjRPi5pzB15VVTuSvAi4IclX+jurqpLUbBt2vww2Axx//PGLLEOS1G9RZ+5VtaP7uQv4JHAq8ECSYwC6n7vm2PbSqpqsqsmJiYnFlCFJmmHB4Z7k+UkO37sM/DRwF3AdsKkbtgm4drFFSpLmZzHTMkcDn0yydz8fqaq/S/JF4Ook5wH3A+csvkxJ0nwsONyr6uvAKbO0Pwi8bjFFSZIWxztUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgxX5Zh6T9wUcy7gra8qZZv2NoRfHMXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatDIwj3JGUnuS7I1yYWjOo4k6blGEu5JDgI+CJwJnAy8McnJoziWJOm5RnXmfiqwtaq+XlXfBz4GbBzRsSRJM4wq3NcC2/rWt3dtkqRlMLbPc0+yGdjcrX4nyX3jqqVBa4Bvj7uIQeJHkB+IVsRrkzevmBfnj8zVMapw3wGs61s/rmt7WlVdClw6ouMf0JJMVdXkuOuQZvK1uXxGNS3zReCkJCckeR5wLnDdiI4lSZphJGfuVbUnyQXAp4CDgMur6u5RHEuS9Fwjm3OvquuB60e1f+2T013aX/naXCapWvlfBCtJejY/fkCSGmS4S1KDDHdJatDYbmLS0kryA8ApwLHA94C7qmrXeKuSepK8CHglfa9PYKqqnhprYQ3zDdUVLsmJwH8C/g3wNWAaOBR4CfA48N+ALf4j0jgkeQ1wIXAk8CVgF8+8Pk8EPg68t6oeHVuRjTLcV7gkHwUuAT5XM/4yu7OlNwEPV9WWcdSnA1uSPwH+a1X9v1n6VgE/AxxUVdcse3GNM9wlqUG+odqoJJNJjh13HdJskmxM8vJx19Ey31Bt168D/zrJV6vqF8ddjDTDy4EfT7Kqqs4cdzEtclqmcUkOr6rHxl2HpOVluDcgyQuBM3jmC1F2AJ+qqt1jK0oaIMnrq+qGcdfRKufcV7gkbwVuA04HDuserwFu7fqk/dVl4y6gZZ65r3DdN1i9fOZZepIjgJur6iVjKUwCksz1PQ4BXltVz1/Oeg4kvqG68gWY7Tf0U12fNE6vBn4J+M6M9gCnLn85Bw7DfeW7GLgtyad55kvJjwdeD/znsVUl9XwBeLyq/n5mh9+bPFpOy6xwSQKsBt7Ac99QfXjvmJl3r0rLYZjXnq/P0fDMfeW7CbgGuLb/Fu8kz0vyWmBTN+aK8ZSnA9xNSWZ9fQKvwtfnyHjmvsIlORT4d8CbgROA3fQ+mOkg4NPAh6rqS2MrUAc0X5/jY7g3JMnBwBrge17jrv2Nr8/lZbhLUoO8iUmSGmS4S1KDDHdpDkneluSuJHcnefu465Hmw3CXZpHkXwH/gd5dlKcAP5PkxeOtShqe4S7N7sfofTbP41W1B/h74N+OuSZpaIa7NLu7gFcnOSrJYcBZwLox1yQNzTtUpVlU1b1J/ojejTbfBW4HnhxrUdI8eJ27NIQkfwhsr6oPjbsWaRieuUtzSPKiqtqV5Hh68+2njbsmaViGuzS3a5IcBfwzcL63zGslcVpGkhrk1TKS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBv1/Fzwv0SaByCUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = ['blue','orange']\n",
    "\n",
    "target_count = y_train.value_counts()\n",
    "target_count.plot(kind='bar', title='Count (target)', color = color);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297 new random picked points\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_resample(X_train_imp, y_train)\n",
    "\n",
    "print(X_ros.shape[0] - X_train_imp.shape[0], 'new random picked points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "9  \n",
      "0.0    321\n",
      "1.0    321\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = y_ros.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = y_ros[y_ros == 0]\n",
    "df_class_1 = y_ros[y_ros == 1]\n",
    "\n",
    "df_test_over = pd.concat([df_class_0, df_class_1], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.value_counts())\n",
    "\n",
    "df_test_over.value_counts().plot(kind='bar', title='Count (target)',color = color);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training took 2.78 seconds\n",
      "Best cross-validation score: 0.78\n",
      "Test set score: 0.15\n",
      "Best parameters: {'classifier': SVC(C=1500, gamma=1), 'classifier__C': 1500, 'classifier__gamma': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy\n",
    "y_ros_array = y_ros.to_numpy().ravel()\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_ros, y_ros_array)\n",
    "   \n",
    "print(\"Model training took %.2f seconds\"\n",
    "    % ((time() - start)))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test_imp, y_test)))\n",
    "print(\"Best parameters: {}\\n\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "9  \n",
      "0.0    321\n",
      "1.0    321\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_train_imp, y_train)\n",
    "# Convert to numpy\n",
    "y_sm_array = y_ros.to_numpy().ravel() \n",
    "# Divide by class\n",
    "df_class_0 = y_sm[y_sm == 0]\n",
    "df_class_1 = y_sm[y_sm == 1]\n",
    "\n",
    "df_test_over = pd.concat([df_class_0, df_class_1], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training took 2.38 seconds\n",
      "Best cross-validation score: 0.84\n",
      "Test set score: 0.10\n",
      "Best parameters: {'classifier': SVC(C=1500, gamma=1), 'classifier__C': 1500, 'classifier__gamma': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "grid_search.fit(X_sm, y_sm_array)\n",
    "   \n",
    "print(\"Model training took %.2f seconds\"\n",
    "    % ((time() - start)))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test_imp, y_test)))\n",
    "print(\"Best parameters: {}\\n\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training took 3.53 seconds\n",
      "Best cross-validation score: 0.83\n",
      "Test set score: 0.10\n",
      "Best parameters: {'classifier': SVC(C=1500, gamma=1), 'classifier__C': 1500, 'classifier__gamma': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='auto')\n",
    "X_smt, y_smt = smt.fit_resample(X_train_imp, y_train)\n",
    "# Convert to numpy array\n",
    "y_smt_array = y_smt.to_numpy().ravel() \n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_smt, y_smt_array)\n",
    "   \n",
    "print(\"Model training took %.2f seconds\"\n",
    "    % ((time() - start)))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test_imp, y_test)))\n",
    "print(\"Best parameters: {}\\n\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we have created the NaN values as requsted then we fill the NaN Imputation method(KNNImputer(n_neighbors=5, weights=\"uniform\"),Then we have trained our first model (Best parameters: {'classifier': SVC(C=1250, gamma=1), 'classifier__C': 1250, 'classifier__gamma': 1}, CV score was 97% and test set score was 96%. Afte that we have tested many different outlier method (OneClassSVM(gamma=1, nu=0.05) and the score was 44%. And finally we can say we have tried differnt over sampling but score did not improve acctually. The best score comes from the random over sampling \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 628cba5] coding finished\n",
      " 1 file changed, 124 insertions(+), 155 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in Assignment 6.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    }
   ],
   "source": [
    "! git commit -am \"coding finished\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
